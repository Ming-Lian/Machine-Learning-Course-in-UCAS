<a name="content">目录</a>

[学习笔记：神经网络与深度学习](#title)
- [第一周：深度学习概论](#introduction)
	- [什么是神经网络](#neural-network)
	- [用神经网络进行监督学习](#supervised-learning-with-neural-network)
	- [深度学习兴起的原因](#reason-of-boom)
- [第二周：神经网络基础](#basic-neural-network)
	- [二分分类及符号约定](#binary-classification-and-sign)
	- [logistic回归](#logistic-regression)
	- [logistic回归损失函数](#loss-function)
	- [损失函数优化方法：梯度下降法](#gradiant-descent)
	- [导数基础知识](#basic-deviation)
	- [计数图与计数图导数](#computation-graph-deviation)
	- [logistic回归中的梯度下降法](#gradient-descent-on-logistic-regression)
		- [只考虑一个样本时](#single-sample)
		- [考虑m个样本时](#m-samples)
	- [向量化技术](#vectorization)
	- [向量化 logistic 回归](#vectorizing-logistic-regression)
	- [Python/numpy 向量的说明](#vector-in-numpy)
	- [logistic 回归成本函数证明](#origin-of-cost-function-in-logistic-regression)



<h1 name="title">学习笔记：神经网络与深度学习</h1>

<a name="introduction"><h3>第一周：深度学习概论 [<sup>目录</sup>](#content)</h3></a>

<h4 name="neural-network">什么是神经网络</h4>

<img src=/picture/NeuralNetwork&DeepLearning-Week1-1.jpg width="800" />

<img src=/picture/NeuralNetwork&DeepLearning-Week1-2-1.jpg width="800" />

<h4 name="supervised-learning-with-neural-network">用神经网络进行监督学习</h4>

<img src=/picture/NeuralNetwork&DeepLearning-Week1-2-2.jpg width="800" />

<img src=/picture/NeuralNetwork&DeepLearning-Week1-3-1.jpg width="800" />

<h4 name="reason-of-boom">深度学习兴起的原因</h4>

<img src=/picture/NeuralNetwork&DeepLearning-Week1-curve.png width="800" />

<img src=/picture/NeuralNetwork&DeepLearning-Week1-3-2.jpg width="800" />

<a name="basic-neural-network"><h3>第二周：神经网络基础 [<sup>目录</sup>](#content)</h3></a>

<h4 name="binary-classification-and-sign">二分分类及符号约定</h4>

<img src=/picture/NeuralNetwork&DeepLearning-Week2-1-1.jpg width="800" />

<h4 name="logistic-regression">logistic回归</h4>

<img src=/picture/NeuralNetwork&DeepLearning-Week2-1-2.jpg width="800" />

<h4 name="loss-function">logistic回归损失函数</h4>

<img src=/picture/NeuralNetwork&DeepLearning-Week2-2.jpg width="800" />

<img src=/picture/NeuralNetwork&DeepLearning-Week2-3-1.jpg width="800" />

<h4 name="gradiant-descent">损失函数优化方法：梯度下降法</h4>

<img src=/picture/NeuralNetwork&DeepLearning-Week2-3-2.jpg width="800" />

<h4 name="basic-deviation">导数基础知识</h4>

<p align="center"><img src=/picture/NeuralNetwork&DeepLearning-Week2-deviation-formula.png width="400" /></p>

<h4 name="computation-graph-deviation">计数图与计数图导数</h4>

<img src=/picture/NeuralNetwork&DeepLearning-Week2-3-3.jpg width="800" />

微积分链式法则

<img src=/picture/NeuralNetwork&DeepLearning-Week2-4-1.jpg width="800" />

<h4 name="gradient-descent-on-logistic-regression">logistic回归中的梯度下降法</h4>

<a name="single-sample">只考虑一个样本时</a>

<img src=/picture/NeuralNetwork&DeepLearning-Week2-4-2.jpg width="800" />

<a name="m-samples">考虑m个样本时</a>

<img src=/picture/NeuralNetwork&DeepLearning-Week2-5.jpg width="800" />

<h4 name="vectorization">向量化技术</h4>

<img src=/picture/NeuralNetwork&DeepLearning-Week2-6.jpg width="800" />

用向量化方法优化logistic回归中的第二个for循环

<table>
<tr>
	<td><img src=/picture/NeuralNetwork&DeepLearning-Week2-gradientDescent-code-non-vectorized.jpg width="400" /></td>
	<td><img src=/picture/NeuralNetwork&DeepLearning-Week2-gradientDescent-code-vectorized.jpg width="400" /></td>
</tr>
</table>

<h4 name="vectorizing-logistic-regression">向量化 logistic 回归</h4>

<img src=/picture/NeuralNetwork&DeepLearning-Week2-6-2.jpg width="800" />

<img src=/picture/NeuralNetwork&DeepLearning-Week2-7-1.jpg width="800" />

<table>
<tr>
	<td><img src=/picture/NeuralNetwork&DeepLearning-Week2-gradientDescent-code-non-vectorized.jpg width="500" /></td>
	<td><img src=/picture/NeuralNetwork&DeepLearning-Week2-bp-vectorized.jpg width="200" /></td>
</tr>
</table>

<h4 name="vector-in-numpy">Python/numpy 向量的说明</h4>

<img src=/picture/NeuralNetwork&DeepLearning-Week2-7-2.jpg width="800" />

<img src=/picture/NeuralNetwork&DeepLearning-Week2-8-1.jpg width="800" />

<h4 name="origin-of-cost-function-in-logistic-regression">logistic 回归成本函数证明</h4>

<img src=/picture/NeuralNetwork&DeepLearning-Week2-8-2.jpg width="800" />
